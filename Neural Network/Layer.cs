using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;
using System.Threading.Tasks;
using NN_PROGLAN.Utils;

namespace NN_PROGLAN.Neural_Network
{
    public class Layer
    {
        private int numOfInputs;
        private int numOfOutputs;

        public double[] Inputs { get; set; }
        public double[] Outputs { get; set; }

        public Neuron[] Neurons { get; set; }

        public double[] Gradient { get; set; }
        public double[] Error { get; set; }

        public double Loss { get; set; }
        public double RoundedError { get; set; }

        public static Random random = new Random();

        public Layer(int numOfInputs, int numOfOutputs)
        {
            this.numOfInputs = numOfInputs;
            this.numOfOutputs = numOfOutputs;

            Inputs = new double[numOfInputs];
            Outputs = new double[numOfOutputs];
            Neurons = new Neuron[numOfOutputs];

            Gradient = new double[numOfOutputs];
            Error = new double[numOfOutputs];

            InitializeWeights();
        }

        private void InitializeWeights()
        {
            for (int i = 0; i < numOfOutputs; i++)
            {
                Neurons[i] = new Neuron() {
                    Weights = new double[numOfInputs],
                    WeightsDelta = new double[numOfInputs],
                    Bias = 0
                };
                for (int j = 0; j < numOfInputs; j++)
                {
                    // 𝘐𝘯𝘪𝘵𝘪𝘢𝘭𝘪𝘻𝘦 𝘢𝘭𝘭 𝘵𝘩𝘦 𝘓𝘢𝘺𝘦𝘳'𝘴 𝘞𝘦𝘪𝘨𝘩𝘵𝘴 𝘸𝘪𝘵𝘩 𝘢 𝘚𝘵𝘢𝘯𝘥𝘢𝘳𝘥 𝘋𝘦𝘷𝘪𝘢𝘵𝘰𝘯 (𝜇) 𝘰𝘧 0.5
                    Neurons[i].Weights[j] = (double)random.NextDouble() - 0.5;
                }
            }
        }

        public double[] ForwardPropagate(double[] inputs)
        {
            Inputs = (double[])inputs.Clone();
            /* ===============================================================================
             * 𝘛𝘩𝘪𝘴 𝘱𝘳𝘰𝘤𝘦𝘴𝘴 𝘪𝘴 𝘳𝘦𝘢𝘭𝘭𝘺 𝘦𝘢𝘴𝘺!
             * 
             *      𝑊ˡ = (𝑤₁, 𝑤₂, 𝑤₃ ... 𝑤ₙ)
             *      𝑧ˡ  = (𝑊ˡ · 𝑎ˡ⁻² + 𝑏ˡ)  𝘙𝘢𝘸 𝘖𝘶𝘵𝘱𝘶𝘵 𝘰𝘧 this 𝘓𝘢𝘺𝘦𝘳
             *      𝑎ˡ  = σ(𝑧ˡ)             𝘈𝘤𝘵𝘪𝘷𝘢𝘵𝘦𝘥/𝘍𝘪𝘯𝘢𝘭 𝘖𝘶𝘵𝘱𝘶𝘵 𝘰𝘧 this 𝘓𝘢𝘺𝘦𝘳
             *      
             * =============================================================================== */
            for (int i = 0; i < numOfOutputs; i++)
            {
                for (int j = 0; j < numOfInputs; j++)
                {
                    // 𝑧ˡ = 𝑊ˡ · 𝑎ˡ⁻²
                    Outputs[i] += inputs[j] * Neurons[i].Weights[j];
                }
                // 𝑧ˡ = 𝑧ˡ + 𝑏ˡ
                Outputs[i] += Neurons[i].Bias;
                // 𝑎ˡ  = σ(𝑧ˡ)
                Outputs[i] = Activation.Sigmoid(Outputs[i]);
            }
            return Outputs;
        }

        public void BackPropOutput(double[] expected)
        {
            /* ===============================================================================
             * 𝘓𝘦𝘵'𝘴 𝘥𝘰 𝘵𝘩𝘦 𝘊𝘩𝘢𝘪𝘯 𝘙𝘶𝘭𝘦!
             * 
             *      𝐸   = 𝘔𝘚𝘌 𝘓𝘰𝘴𝘴 𝘍𝘶𝘯𝘤𝘵𝘪𝘰𝘯
             *      𝑧ˡ  = 𝘙𝘢𝘸 𝘖𝘶𝘵𝘱𝘶𝘵 𝘰𝘧 𝘖𝘶𝘵𝘱𝘶𝘵 𝘓𝘢𝘺𝘦𝘳
             *      𝑊ˡ = 𝘞𝘦𝘪𝘨𝘩𝘵𝘴 𝘰𝘧 𝘵𝘩𝘦 𝘓𝘢𝘴𝘵 𝘓𝘢𝘺𝘦𝘳
             *  
             * 𝘛𝘩𝘦 𝘥𝘦𝘳𝘪𝘷𝘢𝘵𝘪𝘷𝘦 𝘰𝘧 𝐸 𝘞𝘙𝘛 𝑊ˡ 𝘪𝘴 𝘦𝘲𝘶𝘢𝘭 𝘵𝘰 𝘵𝘩𝘦 𝘥𝘦𝘳𝘪𝘷𝘢𝘵𝘦 𝘰𝘧 𝘵𝘩𝘦 𝐸 𝘞𝘙𝘛 𝑧ˡ 𝘮𝘶𝘭𝘵𝘪𝘱𝘭𝘪𝘦𝘥 𝘣𝘺 
             * 𝘵𝘩𝘦 𝘥𝘦𝘳𝘪𝘷𝘢𝘵𝘦 𝘰𝘧 𝘵𝘩𝘦 𝑧ˡ 𝘞𝘙𝘛 ∂𝑊ˡ:
             *  
             *        ∂𝐸      ∂𝐸     ∂𝑧ˡ
             *       ————  = ———— · ————
             *       ∂𝑊ˡ    ∂𝑧ˡ     ∂𝑊ˡ
             * ============================================================================== */

            for (int i = 0; i < numOfOutputs; i++)
            {
                /* ==========================================================================
                 *       ŷ = 𝘰𝘶𝘵𝘱𝘶𝘵 𝘰𝘧 𝘵𝘩𝘦 𝘯𝘦𝘵𝘸𝘰𝘳𝘬
                 *       𝑦 = 𝘦𝘹𝘱𝘦𝘤𝘵𝘦𝘥 𝘰𝘶𝘵𝘱𝘶𝘵
                 * 𝘐𝘯 𝘵𝘩𝘪𝘴 𝘤𝘢𝘴𝘦 𝐸 𝘪𝘴 𝘴𝘪𝘮𝘱𝘭𝘺  𝘥𝘪𝘧𝘧𝘦𝘳𝘦𝘯𝘤𝘦 𝘣𝘦𝘵𝘸𝘦𝘦𝘯 𝘵𝘩𝘦 ŷ 𝘢𝘯𝘥 𝑦:
                 * 
                 *                              𝘞𝘦 𝘸𝘪𝘭𝘭 𝘯𝘰𝘵 𝘤𝘢𝘭𝘤𝘶𝘭𝘢𝘵𝘦 𝘮𝘦𝘢𝘯 𝘴𝘲𝘶𝘢𝘳𝘦𝘥 
                 *       𝐸 =  (ŷ - 𝑦)           𝘣𝘦𝘤𝘢𝘶𝘴𝘦 𝘵𝘩𝘦 𝘣𝘢𝘵𝘤𝘩 𝘴𝘪𝘻𝘦 = 1
                 *            
                 * ========================================================================== */
                Error[i] = Outputs[i] - expected[i];
                // 𝘛𝘩𝘪𝘴 𝘪𝘴 𝘧𝘰𝘳 𝘮𝘰𝘯𝘪𝘵𝘰𝘳𝘪𝘯𝘨 𝘱𝘶𝘳𝘱𝘰𝘴𝘦𝘴 𝘰𝘯𝘭𝘺
                if (expected[i] != 0.0)
                    RoundedError = -Error[i];
            }

            for (int i = 0; i < numOfOutputs; i++)
            {
                /* ==========================================================================
                 *       𝑧ˡ = (𝑊ˡ · 𝑎ˡ⁻¹ + 𝑏ˡ)      𝘓𝘢𝘴𝘵 𝘓𝘢𝘺𝘦𝘳 𝘙𝘢𝘸 𝘖𝘶𝘵𝘱𝘶𝘵
                 *       𝑎ˡ = σ(𝑧ˡ)                 𝘓𝘢𝘴𝘵 𝘓𝘢𝘺𝘦𝘳 𝘚𝘪𝘨𝘮𝘰𝘪𝘥 𝘈𝘤𝘵𝘪𝘷𝘢𝘵𝘦𝘥 𝘖𝘶𝘵𝘱𝘶𝘵 
                 *       
                 * 𝘛𝘩𝘦 𝘧𝘪𝘳𝘴𝘵 𝘵𝘦𝘳𝘮, 𝘸𝘩𝘪𝘤𝘩 𝘪𝘴 𝘥𝘦𝘳𝘪𝘷𝘢𝘵𝘪𝘷𝘦 𝘰𝘧 𝘵𝘩𝘦 𝐸 𝘞𝘙𝘛 𝑧ˡ, 𝘪𝘴 𝐸 𝘮𝘶𝘭𝘵𝘪𝘱𝘭𝘪𝘦𝘥 𝘣𝘺 𝑎ˡ 𝘱𝘳𝘪𝘮𝘦:
                 * 
                 *        ∂𝐸  
                 *       ———— = (ŷ - 𝑦) · ′σ(𝑧ˡ)    𝘧𝘪𝘳𝘴𝘵 𝘵𝘦𝘳𝘮
                 *        ∂𝑧ˡ    
                 * ========================================================================== */
                Gradient[i] = Error[i] * Activation.SigmoidPrime(Outputs[i]);
            }

            for (int i = 0; i < numOfOutputs; i++)
            {
                for (int j = 0; j < numOfInputs; j++)
                {
                    /* ======================================================================
                     *       𝑎ˡ⁻¹ = 𝘗𝘳𝘦𝘤𝘦𝘥𝘪𝘯𝘨 𝘓𝘢𝘺𝘦𝘳 𝘖𝘶𝘵𝘱𝘶𝘵 / 𝘐𝘯𝘱𝘶𝘵 𝘰𝘧 𝘵𝘩𝘪𝘴 𝘓𝘢𝘺𝘦𝘳
                     *       
                     * 𝘛𝘩𝘦 𝘴𝘦𝘤𝘰𝘯𝘥 𝘵𝘦𝘳𝘮, 𝘸𝘩𝘪𝘤𝘩 𝘪𝘴 𝘥𝘦𝘳𝘪𝘷𝘢𝘵𝘪𝘷𝘦 𝘰𝘧 𝘵𝘩𝘦 𝑧ˡ 𝘞𝘙𝘛 𝑊ˡ, is simply 𝑎ˡ⁻¹
                     * 
                     *      ∂𝑧ˡ
                     *     ———— = 𝑎ˡ⁻¹
                     *     ∂𝑊ˡ 
                     *     
                     * 𝘗𝘶𝘵𝘵𝘪𝘯𝘨 𝘪𝘵 𝘢𝘭𝘭 𝘵𝘰𝘨𝘦𝘵𝘩𝘦𝘳:
                     * 
                     *        ∂𝐸  
                     *       ————  = (ŷ - 𝑦) · ′σ(𝑧ˡ) · 𝑎ˡ⁻¹ᵀ 
                     *       ∂𝑊ˡ
                     * 
                     * 𝘞𝘦𝘪𝘨𝘩𝘵𝘴 𝘥𝘦𝘭𝘵𝘢:
                     * 
                     *              ∂𝐸           
                     *      𝑊ˡΔ = —————  = (ŷ - 𝑦) · ′σ(𝑧ˡ) · 𝑎ˡ⁻¹ᵀ
                     *             ∂𝑊ˡ      
                     * ====================================================================== */
                    Neurons[i].WeightsDelta[j] = Gradient[i] * Inputs[j];
                }
                /* ==========================================================================
                 * 𝘉𝘪𝘢𝘴 𝘥𝘦𝘭𝘵𝘢 𝘪𝘴 𝘴𝘪𝘮𝘱𝘭𝘺:
                 * 
                 *              ∂𝐸           
                 *      𝐵ˡΔ =  ———— = (ŷ - 𝑦) · ′σ(𝑧ˡ)
                 *             ∂𝑊ˡ  
                 * ========================================================================== */
                Neurons[i].BiasDelta = Gradient[i];
            }
        }

        public void BackPropHiddenLayer(double[] gradientForward, Neuron[] neurons)
        {
            /* ==============================================================================
             * 𝘕𝘦𝘹𝘵...
             * 
             *      𝑊ˡ⁻¹ = 𝘞𝘦𝘪𝘨𝘩𝘵𝘴 𝘰𝘧 𝘵𝘩𝘦 Hidden 𝘓𝘢𝘺𝘦𝘳s
             *      𝑧ˡ⁻¹   = 𝘗𝘳𝘦𝘤𝘦𝘥𝘪𝘯𝘨 𝘓𝘢𝘺𝘦𝘳 𝘙𝘢𝘸 𝘖𝘶𝘵𝘱𝘶𝘵
             *      
             *      
             * 𝘛𝘩𝘦 𝘥𝘦𝘳𝘪𝘷𝘢𝘵𝘪𝘷𝘦 𝘰𝘧 𝐸 𝘞𝘙𝘛 𝑊ˡ⁻¹ 𝘪𝘴 𝘦𝘲𝘶𝘢𝘭 𝘵𝘰 𝘵𝘩𝘦 𝘥𝘦𝘳𝘪𝘷𝘢𝘵𝘦 𝘰𝘧 𝘵𝘩𝘦 𝐸 𝘞𝘙𝘛 𝑧ˡ⁻¹
             * 𝘮𝘶𝘭𝘵𝘪𝘱𝘭𝘪𝘦𝘥 𝘣𝘺 𝘵𝘩𝘦 𝘥𝘦𝘳𝘪𝘷𝘢𝘵𝘦 𝘰𝘧 𝘵𝘩𝘦 𝑧ˡ⁻¹ 𝘞𝘙𝘛 𝑊ˡ⁻¹:
             *  
             *        ∂𝐸       ∂𝐸      ∂𝑧ˡ⁻¹
             *       ————  =  ————  · ——————
             *       ∂𝑊ˡ⁻¹    ∂𝑧ˡ⁻¹    ∂𝑊ˡ⁻¹
             * ============================================================================= */
            for (int i = 0; i < numOfOutputs; i++)
            {
                /* =========================================================================
                 * For the first term:
                 * 
                 *        ∂𝐸        ∂𝐸      ∂𝑧ˡ      ∂𝑎ˡ⁻¹
                 *       —————  = ————— · —————— · ——————  
                 *        ∂𝑧ˡ⁻¹     ∂𝑧ˡ    ∂𝑎ˡ⁻¹     ∂𝑧ˡ⁻¹ 
                 * 
                 *        
                 * Where
                 *       ∂𝐸
                 *     —————  = δˡ⁺¹ = (ŷ - 𝑦) · ′σ(𝑧ˡ)     𝘚𝘶𝘣𝘴𝘦𝘲𝘶𝘦𝘯𝘵 𝘓𝘢𝘺𝘦𝘳 𝘎𝘳𝘢𝘥𝘪𝘦𝘯𝘵
                 *       ∂𝑧ˡ
                 *       
                 *       ∂𝑧ˡ
                 *     —————— = 𝑊ˡ⁻¹                       𝘞𝘦𝘪𝘨𝘩𝘵𝘴 𝘰𝘧 𝘵𝘩𝘦 𝘤𝘶𝘳𝘳𝘦𝘯𝘵 Hidden 𝘓𝘢𝘺𝘦𝘳
                 *      ∂𝑎ˡ⁻¹
                 *      
                 *      ∂𝑎ˡ⁻¹
                 *     —————— = ′σ(𝑧ˡ⁻¹)                    𝘋𝘦𝘳𝘪𝘷𝘢𝘵𝘪𝘷𝘦 𝘰𝘧 𝘗𝘳𝘦𝘤𝘦𝘥𝘪𝘯𝘨 𝘓𝘢𝘺𝘦𝘳 𝘖𝘶𝘵𝘱𝘶𝘵 
                 *      ∂𝑧ˡ⁻¹
                 *      
                 * ========================================================================= */
                for (int j = 0; j < gradientForward.Length; j++)
                {
                    /* =====================================================================
                     *       ∂𝐸      ∂𝑧ˡ
                     *     ————— · ——————  = δˡ⁺¹ · 𝑊ˡ⁻¹
                     *       ∂𝑧ˡ    ∂𝑎ˡ⁻¹
                     * ===================================================================== */
                    Gradient[i] += gradientForward[j] * neurons[j].Weights[i];
                }
                /* =========================================================================
                * 𝘈𝘭𝘵𝘰𝘨𝘦𝘵𝘩𝘦𝘳, 𝘵𝘩𝘦 𝘧𝘪𝘳𝘴𝘵 𝘵𝘦𝘳𝘮 𝘪𝘴:
                * 
                *        ∂𝐸        
                *       —————  = δˡ⁺¹ · 𝑊ˡ · ′σ(𝑧ˡ⁻¹) 
                *        ∂𝑧ˡ⁻¹     
                * ========================================================================== */
                Gradient[i] *= Activation.SigmoidPrime(Outputs[i]);
            }

            for (int i = 0; i < numOfOutputs; i++)
            {
                for (int j = 0; j < numOfInputs; j++)
                {

                    /* =====================================================================
                     * 𝘛𝘩𝘦 𝘴𝘦𝘤𝘰𝘯𝘥 𝘵𝘦𝘳𝘮 𝘪𝘴 𝘴𝘪𝘮𝘱𝘭𝘺:
                     * 
                     *       ∂𝑧ˡ⁻¹
                     *      ——————  = 𝑎ˡ⁻²ᵀ          𝘗𝘳𝘦𝘤𝘦𝘥𝘪𝘯𝘨 𝘓𝘢𝘺𝘦𝘳 𝘖𝘶𝘵𝘱𝘶𝘵 / 𝘐𝘯𝘱𝘶𝘵 𝘰𝘧 𝘵𝘩𝘪𝘴 𝘓𝘢𝘺𝘦𝘳       
                     *      ∂𝑊ˡ⁻¹
                     *      
                     * 𝘗𝘶𝘵𝘵𝘪𝘯𝘨 𝘪𝘵 𝘢𝘭𝘭 𝘵𝘰𝘨𝘦𝘵𝘩𝘦𝘳:
                     * 
                     *        ∂𝐸       ∂𝐸      ∂𝑧ˡ⁻¹
                     *       ————  =  ————  · ——————
                     *       ∂𝑊ˡ⁻¹    ∂𝑧ˡ⁻¹    ∂𝑊ˡ⁻¹
                     *       
                     *        ∂𝐸             
                     *       —————  =  δˡ⁺¹ · 𝑊ˡ · ′σ(𝑧ˡ⁻¹)  ·   𝑎ˡ⁻²ᵀ
                     *       ∂𝑊ˡ⁻¹    
                     *     
                     * 𝘞𝘦𝘪𝘨𝘩𝘵𝘴 𝘥𝘦𝘭𝘵𝘢:
                     * 
                     *                ∂𝐸            
                     *      𝑊ˡ⁻¹Δ = —————  =  δˡ⁺¹ · 𝑊ˡ · ′σ(𝑧ˡ⁻¹)  ·   𝑎ˡ⁻²ᵀ
                     *               ∂𝑊ˡ⁻¹         
                     * ===================================================================== */
                    Neurons[i].WeightsDelta[j] = Gradient[i] * Inputs[j];
                }
                /* =========================================================================
                 * 𝘉𝘪𝘢𝘴 𝘥𝘦𝘭𝘵𝘢:
                 * 
                 *                 ∂𝐸           
                 *      𝐵ˡ⁻¹Δ = Σ —————
                 *                ∂𝑊ˡ⁻¹  
                 * ========================================================================= */
                Neurons[i].BiasDelta = Gradient[i];
            }

        }

        public void UpdateWeightsAndBiases(double learningRate)
        {
            /* =============================================================================
             * 𝘞𝘦 𝘵𝘩𝘦𝘯 𝘶𝘱𝘥𝘢𝘵𝘦 𝘵𝘩𝘦 𝘞𝘦𝘪𝘨𝘩𝘵𝘴 (𝑊) 𝘢𝘯𝘥 𝘉𝘪𝘢𝘴𝘦𝘴 (𝐵) 𝘰𝘧 𝘵𝘩𝘪𝘴 𝘓𝘢𝘺𝘦𝘳 𝘶𝘴𝘪𝘯𝘨 𝘵𝘩𝘦 𝘧𝘰𝘳𝘮𝘶𝘭𝘢:
             * 
             *      𝑊 = 𝑊 - 𝛼𝑊Δ
             *      𝐵 = 𝐵 - 𝛼𝐵Δ    
             *      
             * Where 𝛼 = 𝘓𝘦𝘢𝘳𝘯𝘪𝘯𝘨 𝘙𝘢𝘵𝘦
             * ============================================================================= */
            for (int i = 0; i < numOfOutputs; i++)
            {
                for (int j = 0; j < numOfInputs; j++)
                {
                    // 𝑊 = 𝑊 - 𝛼𝑊Δ
                    Neurons[i].Weights[j] -= Neurons[i].WeightsDelta[j] * learningRate;
                    // 𝐵 = 𝐵 - 𝛼𝐵Δ 
                    Neurons[i].Bias -= Neurons[i].BiasDelta * learningRate;
                }
            }
        }

    }

}
